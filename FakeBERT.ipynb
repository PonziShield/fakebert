{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"gpuType":"T4","mount_file_id":"1rygTfEqVqYuwiwXD4V6FTiSFMWXMUC1m","authorship_tag":"ABX9TyMZ5dc+060m85i2FhGEMMTT"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","source":["#### Setup"],"metadata":{"id":"-1xUJocdinfB"}},{"cell_type":"code","execution_count":1,"metadata":{"id":"sV-akwn3ijIv","executionInfo":{"status":"ok","timestamp":1702875390474,"user_tz":-330,"elapsed":14074,"user":{"displayName":"Nimsara Fernando","userId":"11470797706788239513"}}},"outputs":[],"source":["import torch\n","import torch.nn as nn\n","from transformers import RobertaModel, RobertaTokenizer\n","from torch.utils.data import Dataset, DataLoader\n","import torch.nn.functional as F\n","import torch.optim as optim\n","import numpy as np\n","import pandas as pd\n","from imblearn.under_sampling import RandomUnderSampler\n","from collections import Counter\n","from torch.optim.lr_scheduler import ExponentialLR\n","from sklearn.model_selection import train_test_split\n","\n","import re\n","from bs4 import BeautifulSoup\n","from nltk.tokenize import WordPunctTokenizer"]},{"cell_type":"markdown","source":["----------------------------------------------------------\n","To fix the error `Torch compile: libcuda.so cannot found` raised by\n","```python\n","torch.compile(robertaModel, backend=\"inductor\")\n","```\n","----------------------------------------------------------"],"metadata":{"id":"0O_d76mZirb7"}},{"cell_type":"code","source":["!export LC_ALL=\"en_US.UTF-8\"\n","!export LD_LIBRARY_PATH=\"/usr/lib64-nvidia\"\n","!export LIBRARY_PATH=\"/usr/local/cuda/lib64/stubs\"\n","!ldconfig /usr/lib64-nvidia"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"n_-sajxLipyh","executionInfo":{"status":"ok","timestamp":1702875621040,"user_tz":-330,"elapsed":2865,"user":{"displayName":"Nimsara Fernando","userId":"11470797706788239513"}},"outputId":"93ff03c3-4a37-4920-bec0-8bd74f8ad2fb"},"execution_count":11,"outputs":[{"output_type":"stream","name":"stdout","text":["/sbin/ldconfig.real: /usr/local/lib/libtbbbind_2_5.so.3 is not a symbolic link\n","\n","/sbin/ldconfig.real: /usr/local/lib/libtbb.so.12 is not a symbolic link\n","\n","/sbin/ldconfig.real: /usr/local/lib/libtbbmalloc_proxy.so.2 is not a symbolic link\n","\n","/sbin/ldconfig.real: /usr/local/lib/libtbbbind.so.3 is not a symbolic link\n","\n","/sbin/ldconfig.real: /usr/local/lib/libtbbbind_2_0.so.3 is not a symbolic link\n","\n","/sbin/ldconfig.real: /usr/local/lib/libtbbmalloc.so.2 is not a symbolic link\n","\n"]}]},{"cell_type":"code","source":["# Check for GPU availability\n","device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n","print(device)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"P0zITF70itdY","executionInfo":{"status":"ok","timestamp":1702875390475,"user_tz":-330,"elapsed":7,"user":{"displayName":"Nimsara Fernando","userId":"11470797706788239513"}},"outputId":"642e3901-a6c6-45cd-8462-71f7469cb495"},"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["cuda:0\n"]}]},{"cell_type":"markdown","source":["#### Dataset"],"metadata":{"id":"CyWLm66_iwzH"}},{"cell_type":"code","source":["train_csv_url = \"/content/drive/MyDrive/#Semester07/FYP/FakeNews/fake-news/train.csv\"\n","train_data = pd.read_csv(train_csv_url)\n","train_data.head()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":238},"id":"j12t3Jvaiu-m","executionInfo":{"status":"ok","timestamp":1702799237605,"user_tz":-330,"elapsed":4931,"user":{"displayName":"Nimsara Fernando","userId":"11470797706788239513"}},"outputId":"1be09fe3-dac4-4e5f-e9ef-244da622b887"},"execution_count":3,"outputs":[{"output_type":"execute_result","data":{"text/plain":["   id                                              title              author  \\\n","0   0  House Dem Aide: We Didn’t Even See Comey’s Let...       Darrell Lucus   \n","1   1  FLYNN: Hillary Clinton, Big Woman on Campus - ...     Daniel J. Flynn   \n","2   2                  Why the Truth Might Get You Fired  Consortiumnews.com   \n","3   3  15 Civilians Killed In Single US Airstrike Hav...     Jessica Purkiss   \n","4   4  Iranian woman jailed for fictional unpublished...      Howard Portnoy   \n","\n","                                                text  label  \n","0  House Dem Aide: We Didn’t Even See Comey’s Let...      1  \n","1  Ever get the feeling your life circles the rou...      0  \n","2  Why the Truth Might Get You Fired October 29, ...      1  \n","3  Videos 15 Civilians Killed In Single US Airstr...      1  \n","4  Print \\nAn Iranian woman has been sentenced to...      1  "],"text/html":["\n","  <div id=\"df-fc938c05-6b07-42c9-aff4-a01db46ec92e\" class=\"colab-df-container\">\n","    <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>id</th>\n","      <th>title</th>\n","      <th>author</th>\n","      <th>text</th>\n","      <th>label</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>0</td>\n","      <td>House Dem Aide: We Didn’t Even See Comey’s Let...</td>\n","      <td>Darrell Lucus</td>\n","      <td>House Dem Aide: We Didn’t Even See Comey’s Let...</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>1</td>\n","      <td>FLYNN: Hillary Clinton, Big Woman on Campus - ...</td>\n","      <td>Daniel J. Flynn</td>\n","      <td>Ever get the feeling your life circles the rou...</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>2</td>\n","      <td>Why the Truth Might Get You Fired</td>\n","      <td>Consortiumnews.com</td>\n","      <td>Why the Truth Might Get You Fired October 29, ...</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>3</td>\n","      <td>15 Civilians Killed In Single US Airstrike Hav...</td>\n","      <td>Jessica Purkiss</td>\n","      <td>Videos 15 Civilians Killed In Single US Airstr...</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>4</td>\n","      <td>Iranian woman jailed for fictional unpublished...</td>\n","      <td>Howard Portnoy</td>\n","      <td>Print \\nAn Iranian woman has been sentenced to...</td>\n","      <td>1</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","    <div class=\"colab-df-buttons\">\n","\n","  <div class=\"colab-df-container\">\n","    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-fc938c05-6b07-42c9-aff4-a01db46ec92e')\"\n","            title=\"Convert this dataframe to an interactive table.\"\n","            style=\"display:none;\">\n","\n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n","    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n","  </svg>\n","    </button>\n","\n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    .colab-df-buttons div {\n","      margin-bottom: 4px;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","    <script>\n","      const buttonEl =\n","        document.querySelector('#df-fc938c05-6b07-42c9-aff4-a01db46ec92e button.colab-df-convert');\n","      buttonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","      async function convertToInteractive(key) {\n","        const element = document.querySelector('#df-fc938c05-6b07-42c9-aff4-a01db46ec92e');\n","        const dataTable =\n","          await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                    [key], {});\n","        if (!dataTable) return;\n","\n","        const docLinkHtml = 'Like what you see? Visit the ' +\n","          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","          + ' to learn more about interactive tables.';\n","        element.innerHTML = '';\n","        dataTable['output_type'] = 'display_data';\n","        await google.colab.output.renderOutput(dataTable, element);\n","        const docLink = document.createElement('div');\n","        docLink.innerHTML = docLinkHtml;\n","        element.appendChild(docLink);\n","      }\n","    </script>\n","  </div>\n","\n","\n","<div id=\"df-73ec9813-f1d2-4619-b55a-6644ee663c0d\">\n","  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-73ec9813-f1d2-4619-b55a-6644ee663c0d')\"\n","            title=\"Suggest charts\"\n","            style=\"display:none;\">\n","\n","<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","     width=\"24px\">\n","    <g>\n","        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n","    </g>\n","</svg>\n","  </button>\n","\n","<style>\n","  .colab-df-quickchart {\n","      --bg-color: #E8F0FE;\n","      --fill-color: #1967D2;\n","      --hover-bg-color: #E2EBFA;\n","      --hover-fill-color: #174EA6;\n","      --disabled-fill-color: #AAA;\n","      --disabled-bg-color: #DDD;\n","  }\n","\n","  [theme=dark] .colab-df-quickchart {\n","      --bg-color: #3B4455;\n","      --fill-color: #D2E3FC;\n","      --hover-bg-color: #434B5C;\n","      --hover-fill-color: #FFFFFF;\n","      --disabled-bg-color: #3B4455;\n","      --disabled-fill-color: #666;\n","  }\n","\n","  .colab-df-quickchart {\n","    background-color: var(--bg-color);\n","    border: none;\n","    border-radius: 50%;\n","    cursor: pointer;\n","    display: none;\n","    fill: var(--fill-color);\n","    height: 32px;\n","    padding: 0;\n","    width: 32px;\n","  }\n","\n","  .colab-df-quickchart:hover {\n","    background-color: var(--hover-bg-color);\n","    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n","    fill: var(--button-hover-fill-color);\n","  }\n","\n","  .colab-df-quickchart-complete:disabled,\n","  .colab-df-quickchart-complete:disabled:hover {\n","    background-color: var(--disabled-bg-color);\n","    fill: var(--disabled-fill-color);\n","    box-shadow: none;\n","  }\n","\n","  .colab-df-spinner {\n","    border: 2px solid var(--fill-color);\n","    border-color: transparent;\n","    border-bottom-color: var(--fill-color);\n","    animation:\n","      spin 1s steps(1) infinite;\n","  }\n","\n","  @keyframes spin {\n","    0% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","      border-left-color: var(--fill-color);\n","    }\n","    20% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    30% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","      border-right-color: var(--fill-color);\n","    }\n","    40% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    60% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","    }\n","    80% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-bottom-color: var(--fill-color);\n","    }\n","    90% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","    }\n","  }\n","</style>\n","\n","  <script>\n","    async function quickchart(key) {\n","      const quickchartButtonEl =\n","        document.querySelector('#' + key + ' button');\n","      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n","      quickchartButtonEl.classList.add('colab-df-spinner');\n","      try {\n","        const charts = await google.colab.kernel.invokeFunction(\n","            'suggestCharts', [key], {});\n","      } catch (error) {\n","        console.error('Error during call to suggestCharts:', error);\n","      }\n","      quickchartButtonEl.classList.remove('colab-df-spinner');\n","      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n","    }\n","    (() => {\n","      let quickchartButtonEl =\n","        document.querySelector('#df-73ec9813-f1d2-4619-b55a-6644ee663c0d button');\n","      quickchartButtonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","    })();\n","  </script>\n","</div>\n","    </div>\n","  </div>\n"]},"metadata":{},"execution_count":3}]},{"cell_type":"code","source":["test_csv_url = \"/content/drive/MyDrive/#Semester07/FYP/FakeNews/fake-news/test.csv\"\n","test_data = pd.read_csv(test_csv_url)\n","test_data.head()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":221},"id":"UQXlkboilEC9","executionInfo":{"status":"ok","timestamp":1702799239232,"user_tz":-330,"elapsed":1629,"user":{"displayName":"Nimsara Fernando","userId":"11470797706788239513"}},"outputId":"a2e56ed3-2f5b-4401-b610-8209cf3c3d1e"},"execution_count":4,"outputs":[{"output_type":"execute_result","data":{"text/plain":["      id                                              title  \\\n","0  20800  Specter of Trump Loosens Tongues, if Not Purse...   \n","1  20801  Russian warships ready to strike terrorists ne...   \n","2  20802  #NoDAPL: Native American Leaders Vow to Stay A...   \n","3  20803  Tim Tebow Will Attempt Another Comeback, This ...   \n","4  20804                    Keiser Report: Meme Wars (E995)   \n","\n","                    author                                               text  \n","0         David Streitfeld  PALO ALTO, Calif.  —   After years of scorning...  \n","1                      NaN  Russian warships ready to strike terrorists ne...  \n","2            Common Dreams  Videos #NoDAPL: Native American Leaders Vow to...  \n","3            Daniel Victor  If at first you don’t succeed, try a different...  \n","4  Truth Broadcast Network  42 mins ago 1 Views 0 Comments 0 Likes 'For th...  "],"text/html":["\n","  <div id=\"df-9a152287-2e76-4cce-9122-c786b12bbd61\" class=\"colab-df-container\">\n","    <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>id</th>\n","      <th>title</th>\n","      <th>author</th>\n","      <th>text</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>20800</td>\n","      <td>Specter of Trump Loosens Tongues, if Not Purse...</td>\n","      <td>David Streitfeld</td>\n","      <td>PALO ALTO, Calif.  —   After years of scorning...</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>20801</td>\n","      <td>Russian warships ready to strike terrorists ne...</td>\n","      <td>NaN</td>\n","      <td>Russian warships ready to strike terrorists ne...</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>20802</td>\n","      <td>#NoDAPL: Native American Leaders Vow to Stay A...</td>\n","      <td>Common Dreams</td>\n","      <td>Videos #NoDAPL: Native American Leaders Vow to...</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>20803</td>\n","      <td>Tim Tebow Will Attempt Another Comeback, This ...</td>\n","      <td>Daniel Victor</td>\n","      <td>If at first you don’t succeed, try a different...</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>20804</td>\n","      <td>Keiser Report: Meme Wars (E995)</td>\n","      <td>Truth Broadcast Network</td>\n","      <td>42 mins ago 1 Views 0 Comments 0 Likes 'For th...</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","    <div class=\"colab-df-buttons\">\n","\n","  <div class=\"colab-df-container\">\n","    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-9a152287-2e76-4cce-9122-c786b12bbd61')\"\n","            title=\"Convert this dataframe to an interactive table.\"\n","            style=\"display:none;\">\n","\n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n","    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n","  </svg>\n","    </button>\n","\n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    .colab-df-buttons div {\n","      margin-bottom: 4px;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","    <script>\n","      const buttonEl =\n","        document.querySelector('#df-9a152287-2e76-4cce-9122-c786b12bbd61 button.colab-df-convert');\n","      buttonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","      async function convertToInteractive(key) {\n","        const element = document.querySelector('#df-9a152287-2e76-4cce-9122-c786b12bbd61');\n","        const dataTable =\n","          await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                    [key], {});\n","        if (!dataTable) return;\n","\n","        const docLinkHtml = 'Like what you see? Visit the ' +\n","          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","          + ' to learn more about interactive tables.';\n","        element.innerHTML = '';\n","        dataTable['output_type'] = 'display_data';\n","        await google.colab.output.renderOutput(dataTable, element);\n","        const docLink = document.createElement('div');\n","        docLink.innerHTML = docLinkHtml;\n","        element.appendChild(docLink);\n","      }\n","    </script>\n","  </div>\n","\n","\n","<div id=\"df-fdb8d604-9b51-4e79-bb6f-def922d2f3ff\">\n","  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-fdb8d604-9b51-4e79-bb6f-def922d2f3ff')\"\n","            title=\"Suggest charts\"\n","            style=\"display:none;\">\n","\n","<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","     width=\"24px\">\n","    <g>\n","        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n","    </g>\n","</svg>\n","  </button>\n","\n","<style>\n","  .colab-df-quickchart {\n","      --bg-color: #E8F0FE;\n","      --fill-color: #1967D2;\n","      --hover-bg-color: #E2EBFA;\n","      --hover-fill-color: #174EA6;\n","      --disabled-fill-color: #AAA;\n","      --disabled-bg-color: #DDD;\n","  }\n","\n","  [theme=dark] .colab-df-quickchart {\n","      --bg-color: #3B4455;\n","      --fill-color: #D2E3FC;\n","      --hover-bg-color: #434B5C;\n","      --hover-fill-color: #FFFFFF;\n","      --disabled-bg-color: #3B4455;\n","      --disabled-fill-color: #666;\n","  }\n","\n","  .colab-df-quickchart {\n","    background-color: var(--bg-color);\n","    border: none;\n","    border-radius: 50%;\n","    cursor: pointer;\n","    display: none;\n","    fill: var(--fill-color);\n","    height: 32px;\n","    padding: 0;\n","    width: 32px;\n","  }\n","\n","  .colab-df-quickchart:hover {\n","    background-color: var(--hover-bg-color);\n","    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n","    fill: var(--button-hover-fill-color);\n","  }\n","\n","  .colab-df-quickchart-complete:disabled,\n","  .colab-df-quickchart-complete:disabled:hover {\n","    background-color: var(--disabled-bg-color);\n","    fill: var(--disabled-fill-color);\n","    box-shadow: none;\n","  }\n","\n","  .colab-df-spinner {\n","    border: 2px solid var(--fill-color);\n","    border-color: transparent;\n","    border-bottom-color: var(--fill-color);\n","    animation:\n","      spin 1s steps(1) infinite;\n","  }\n","\n","  @keyframes spin {\n","    0% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","      border-left-color: var(--fill-color);\n","    }\n","    20% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    30% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","      border-right-color: var(--fill-color);\n","    }\n","    40% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    60% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","    }\n","    80% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-bottom-color: var(--fill-color);\n","    }\n","    90% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","    }\n","  }\n","</style>\n","\n","  <script>\n","    async function quickchart(key) {\n","      const quickchartButtonEl =\n","        document.querySelector('#' + key + ' button');\n","      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n","      quickchartButtonEl.classList.add('colab-df-spinner');\n","      try {\n","        const charts = await google.colab.kernel.invokeFunction(\n","            'suggestCharts', [key], {});\n","      } catch (error) {\n","        console.error('Error during call to suggestCharts:', error);\n","      }\n","      quickchartButtonEl.classList.remove('colab-df-spinner');\n","      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n","    }\n","    (() => {\n","      let quickchartButtonEl =\n","        document.querySelector('#df-fdb8d604-9b51-4e79-bb6f-def922d2f3ff button');\n","      quickchartButtonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","    })();\n","  </script>\n","</div>\n","    </div>\n","  </div>\n"]},"metadata":{},"execution_count":4}]},{"cell_type":"code","source":["print(f\"train dataset shape {train_data.shape}\")\n","print(f\"# of missing values {train_data.isna().sum()}\")\n","print(f\"label summary\\n{train_data['label'].value_counts()}\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"dAeoNB5AjUb9","executionInfo":{"status":"ok","timestamp":1702799239232,"user_tz":-330,"elapsed":9,"user":{"displayName":"Nimsara Fernando","userId":"11470797706788239513"}},"outputId":"8425b76f-0148-4d1f-989b-1d1856c17d75"},"execution_count":5,"outputs":[{"output_type":"stream","name":"stdout","text":["train dataset shape (20800, 5)\n","# of missing values id           0\n","title      558\n","author    1957\n","text        39\n","label        0\n","dtype: int64\n","label summary\n","1    10413\n","0    10387\n","Name: label, dtype: int64\n"]}]},{"cell_type":"code","source":["filtered_train_data = train_data.copy()\n","\n","# Remove missing values in \"text\" column\n","print(f\"missing value count {filtered_train_data['text'].isna().sum()}\")\n","filtered_train_data.dropna(subset=['text'], inplace=True)\n","\n","# Check for empty strings and drop rows with empty \"text\" values\n","filtered_train_data['text'] = filtered_train_data['text'].str.strip() # Strip whitespace from the \"text\" column\n","print(f\"empty string count {filtered_train_data[filtered_train_data['text'] == ''].shape[0]}\")\n","filtered_train_data = filtered_train_data[filtered_train_data['text'] != '']\n","print(f\"filtered_train_data dataset shape {filtered_train_data.shape}\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"n0-tCze8l0r1","executionInfo":{"status":"ok","timestamp":1702799239233,"user_tz":-330,"elapsed":8,"user":{"displayName":"Nimsara Fernando","userId":"11470797706788239513"}},"outputId":"4db7fe13-cb79-4eff-eb43-8640f8abb4c0"},"execution_count":6,"outputs":[{"output_type":"stream","name":"stdout","text":["missing value count 39\n","empty string count 77\n","filtered_train_data dataset shape (20684, 5)\n"]}]},{"cell_type":"code","source":["x_train, x_temp, y_train, y_temp = train_test_split(filtered_train_data['text'], filtered_train_data['label'], test_size=0.2, stratify=filtered_train_data['label'], random_state=2023)"],"metadata":{"id":"XN1fsnTMlPOt","executionInfo":{"status":"ok","timestamp":1702799239233,"user_tz":-330,"elapsed":4,"user":{"displayName":"Nimsara Fernando","userId":"11470797706788239513"}}},"execution_count":7,"outputs":[]},{"cell_type":"code","source":["x_test, x_valid, y_test, y_valid = train_test_split(x_temp, y_temp, test_size=0.5, stratify=y_temp, random_state=2023)"],"metadata":{"id":"zbZ48KtwmcuJ","executionInfo":{"status":"ok","timestamp":1702799239233,"user_tz":-330,"elapsed":4,"user":{"displayName":"Nimsara Fernando","userId":"11470797706788239513"}}},"execution_count":8,"outputs":[]},{"cell_type":"code","source":["print(f\"y_train\\n {y_train.value_counts()}\")\n","print(f\"y_test\\n {y_test.value_counts()}\")\n","print(f\"y_valid\\n {y_valid.value_counts()}\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"sGrRwqFLmu4Q","executionInfo":{"status":"ok","timestamp":1702799239625,"user_tz":-330,"elapsed":7,"user":{"displayName":"Nimsara Fernando","userId":"11470797706788239513"}},"outputId":"c1d35090-f60d-49eb-a9d0-e5e57f18d01d"},"execution_count":9,"outputs":[{"output_type":"stream","name":"stdout","text":["y_train\n"," 0    8309\n","1    8238\n","Name: label, dtype: int64\n","y_test\n"," 0    1039\n","1    1029\n","Name: label, dtype: int64\n","y_valid\n"," 0    1039\n","1    1030\n","Name: label, dtype: int64\n"]}]},{"cell_type":"markdown","source":["#### Implementation"],"metadata":{"id":"xpy_UV0ynmv6"}},{"cell_type":"code","source":["class FakeBERT(nn.Module):\n","    def __init__(\n","        self,\n","        device,\n","        roberta_model_path='roberta-base',\n","        num_classes=1,\n","        inductor=True\n","        ):\n","        super(FakeBERT, self).__init__()\n","\n","        # Load pre-trained RoBERTa model\n","        self.roberta = RobertaModel.from_pretrained(roberta_model_path).to(device=device)\n","        if (inductor):\n","          self.roberta = torch.compile(self.roberta, backend=\"inductor\")\n","        self.tokenizer = RobertaTokenizer.from_pretrained(roberta_model_path)\n","\n","        # CNN\n","        self.conv1d_p1 = nn.Conv1d(in_channels=768, out_channels=128, kernel_size=5).to(device=device)\n","        self.conv1d_p2 = nn.Conv1d(in_channels=768, out_channels=128, kernel_size=4).to(device=device)\n","        self.conv1d_p3 = nn.Conv1d(in_channels=768, out_channels=128, kernel_size=3).to(device=device)\n","        self.conv1d_s1 = nn.Conv1d(in_channels=128, out_channels=128, kernel_size=5).to(device=device)\n","        self.conv1d_s2 = nn.Conv1d(in_channels=128, out_channels=128, kernel_size=5).to(device=device)\n","\n","        # Pooling\n","        self.max_pool_p1 = nn.MaxPool1d(kernel_size=5).to(device=device)\n","        self.max_pool_p2 = nn.MaxPool1d(kernel_size=5).to(device=device)\n","        self.max_pool_p3 = nn.MaxPool1d(kernel_size=5).to(device=device)\n","        self.max_pool_s1 = nn.MaxPool1d(kernel_size=5).to(device=device)\n","        self.max_pool_s2 = nn.MaxPool1d(kernel_size=10).to(device=device)\n","\n","        # Fully connected layers\n","        self.linear1 = nn.Linear(640, 128).to(device=device)\n","        self.linear2 = nn.Linear(128, num_classes).to(device=device)\n","        self.sigmoid = nn.Sigmoid().to(device=device)\n","\n","    def forward(self, x):\n","        # Tokenize and encode the sentences\n","        tokenized_sentences = self.tokenizer(x, truncation=True, padding='max_length', return_tensors='pt').to(device=device)\n","        # print('tokenized_sentences', tokenized_sentences.shape)\n","\n","        # Forward pass to get embeddings\n","        with torch.no_grad():\n","            # Get RoBERTa embeddings\n","            model_output = self.roberta(**tokenized_sentences)\n","\n","        # Extract embeddings from the output\n","        embeddings = model_output.last_hidden_state\n","        # print('embeddings', embeddings.shape)\n","\n","        output_p1 = self.max_pool_p1(F.relu(self.conv1d_p1(embeddings.permute(0, 2, 1))))\n","        output_p2 = self.max_pool_p2(F.relu(self.conv1d_p2(embeddings.permute(0, 2, 1))))\n","        output_p3 = self.max_pool_p3(F.relu(self.conv1d_p3(embeddings.permute(0, 2, 1))))\n","        output_s = torch.cat((output_p1, output_p2, output_p3), dim=2)\n","        output_s1 = F.relu(self.conv1d_s1(output_s))\n","        output_s1 = self.max_pool_s1(output_s1)\n","        output_s2 = F.relu(self.conv1d_s2(output_s1))\n","        output_s2 = self.max_pool_s2(output_s2)\n","        output_s2 = output_s2.permute(0, 2, 1)\n","        output_f = output_s2.reshape(output_s2.size(0), -1)\n","        output_l1 = torch.relu(self.linear1(output_f))\n","        output_l2 = self.linear2(output_l1)\n","        output = self.sigmoid(output_l2)\n","\n","        return output"],"metadata":{"id":"yGBh2D2pnBnb","executionInfo":{"status":"ok","timestamp":1702875390475,"user_tz":-330,"elapsed":4,"user":{"displayName":"Nimsara Fernando","userId":"11470797706788239513"}}},"execution_count":3,"outputs":[]},{"cell_type":"code","source":["sentences = [\"I love this product!\", \"It's terrible.\", \"Awesome experience.\", \"Worst ever.\", \"Great job!\", \"Awful.\", \"Excellent service.\", \"Hate it.\", \"Fantastic!\", \"Disappointing.\"]\n","labels = [1, 0, 1, 0, 1, 0, 1, 0, 1, 0]\n","\n","# x_train, x_valid, y_train, y_valid = train_test_split(sentences, labels, test_size=0.2, stratify=labels, random_state=2023)\n","\n","# Create DataLoader for training and validation sets\n","batch_size = 128\n","\n","train_dataset = list(zip(x_train, y_train))\n","train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n","\n","val_dataset = list(zip(x_valid, y_valid))\n","val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)\n","\n","# Initialize the model\n","fakebert = FakeBERT(\n","    device,\n","    inductor=False\n",")\n","\n","# Loss function and optimizer\n","criterion = nn.BCELoss().to(device=device)  # Binary Cross-Entropy Loss for binary classification\n","optimizer = optim.Adam(fakebert.parameters(), lr=0.001)\n","\n","d_r = 10**-10\n","scheduler = ExponentialLR(optimizer, gamma=(1.0 - d_r))\n","\n","# Define early stopping parameters\n","patience = 5\n","best_validation_accuracy = 0\n","no_improvement_counter = 0\n","\n","# Training loop\n","num_epochs = 10\n","\n","for epoch in range(num_epochs):\n","    fakebert.train()\n","    total_correct_train = 0\n","    total_samples_train = 0\n","\n","    for inputs, labels in train_loader:\n","        optimizer.zero_grad()\n","        outputs = fakebert(inputs)\n","\n","        # Compute training accuracy\n","        predicted_labels_train = (outputs > 0.5).int()\n","        total_correct_train += (predicted_labels_train.view(-1) == labels.to(device=device)).sum().item()\n","\n","        # Accumulate the sum of batch sizes\n","        total_samples_train += len(labels)\n","\n","        loss = criterion(outputs, torch.as_tensor(labels, dtype=torch.float32).unsqueeze(1).to(device=device))\n","        loss.backward()\n","        optimizer.step()\n","\n","    # Compute training accuracy\n","    train_accuracy = total_correct_train / total_samples_train\n","\n","    # Validation\n","    val_loss = 0.0\n","    total_correct_val = 0\n","    total_samples_val = 0\n","    num_iterations = (len(y_valid) + batch_size - 1) // batch_size\n","\n","    fakebert.eval()\n","    with torch.no_grad():\n","        for val_inputs, val_labels in val_loader:\n","            val_outputs = fakebert(val_inputs)\n","\n","            # Compute validation accuracy\n","            predicted_labels_val = (val_outputs > 0.5).int()\n","            total_correct_val += (predicted_labels_val.view(-1) == val_labels.to(device=device)).sum().item()\n","\n","            # Accumulate the sum of batch sizes\n","            total_samples_val += len(val_labels)\n","\n","            val_batch_targets = torch.as_tensor(val_labels, dtype=torch.float32).unsqueeze(1).to(device=device)\n","            ce = criterion(val_outputs, val_batch_targets).item()\n","            val_loss += ce\n","\n","        avg_val_loss = val_loss / len(val_loader)\n","        val_accuracy = total_correct_val / total_samples_val\n","\n","        print(f'Epoch {epoch + 1}/{num_epochs}, Loss: {avg_val_loss:.4f}, Training Accuracy: {train_accuracy:.4f}, Validation Accuracy: {val_accuracy:.4f}')\n","\n","        # Check for early stopping\n","        if val_accuracy > best_validation_accuracy:\n","            best_validation_accuracy = val_accuracy\n","            no_improvement_counter = 0\n","            # Save the trained best fakebert if needed\n","            torch.save(fakebert.state_dict(), '/content/drive/Shareddrives/test/FYP/fake-news/fakebert.pth')\n","        else:\n","            no_improvement_counter += 1\n","\n","        # If no improvement for 'patience' consecutive epochs, stop training\n","        if no_improvement_counter >= patience:\n","            print(\"Early stopping triggered. Training stopped.\")\n","            break"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ynAFQEzioUDL","executionInfo":{"status":"ok","timestamp":1702805247958,"user_tz":-330,"elapsed":5882483,"user":{"displayName":"Nimsara Fernando","userId":"11470797706788239513"}},"outputId":"d8c357d3-dd0c-49ed-ebb7-924816d7a1ed"},"execution_count":13,"outputs":[{"output_type":"stream","name":"stderr","text":["Some weights of RobertaModel were not initialized from the model checkpoint at roberta-base and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 1/10, Loss: 0.0057, Training Accuracy: 0.9527, Validation Accuracy: 0.9976\n","Epoch 2/10, Loss: 0.0120, Training Accuracy: 0.9966, Validation Accuracy: 0.9947\n","Epoch 3/10, Loss: 0.0037, Training Accuracy: 0.9981, Validation Accuracy: 0.9995\n","Epoch 4/10, Loss: 0.0025, Training Accuracy: 0.9988, Validation Accuracy: 0.9990\n","Epoch 5/10, Loss: 0.0031, Training Accuracy: 0.9996, Validation Accuracy: 0.9990\n","Epoch 6/10, Loss: 0.0023, Training Accuracy: 0.9991, Validation Accuracy: 0.9990\n","Epoch 7/10, Loss: 0.0019, Training Accuracy: 0.9998, Validation Accuracy: 0.9990\n","Epoch 8/10, Loss: 0.0018, Training Accuracy: 0.9997, Validation Accuracy: 0.9995\n","Early stopping triggered. Training stopped.\n"]}]},{"cell_type":"markdown","source":["#### Twitter US Airline Sentiment"],"metadata":{"id":"sWTUhk8e4Sof"}},{"cell_type":"code","source":["file_path = '/content/drive/Shareddrives/test/Sentiment/Tweets.csv'\n","\n","df = pd.read_csv(file_path, usecols=['airline_sentiment', 'text'])\n","df.dropna(subset=['text'], inplace=True)\n","df.dropna(subset=['airline_sentiment'], inplace=True)\n","\n","df['airline_sentiment'] = df['airline_sentiment'].map({'neutral': 2, 'positive': 1, 'negative': 0})\n","\n","valid_sentiments = [0, 1]\n","df_valid = df[df['airline_sentiment'].isin(valid_sentiments)]"],"metadata":{"id":"0Xi0qiQ8o3_8","executionInfo":{"status":"ok","timestamp":1702875489202,"user_tz":-330,"elapsed":695,"user":{"displayName":"Nimsara Fernando","userId":"11470797706788239513"}}},"execution_count":5,"outputs":[]},{"cell_type":"code","source":["df_valid['airline_sentiment'].value_counts()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"qJ5MrKx54s-9","executionInfo":{"status":"ok","timestamp":1702875489817,"user_tz":-330,"elapsed":616,"user":{"displayName":"Nimsara Fernando","userId":"11470797706788239513"}},"outputId":"caf66662-bdf1-44ea-e823-bca30fd9620b"},"execution_count":6,"outputs":[{"output_type":"execute_result","data":{"text/plain":["0    9178\n","1    2363\n","Name: airline_sentiment, dtype: int64"]},"metadata":{},"execution_count":6}]},{"cell_type":"code","source":["# Split the data into training and validation sets\n","x_train, x_temp, y_train, y_temp = train_test_split(df_valid['text'], df_valid['airline_sentiment'], test_size=0.2, stratify=df_valid['airline_sentiment'], random_state=2023)\n","x_test, x_val, y_test, y_val = train_test_split(x_temp, y_temp, test_size=0.5, stratify=y_temp, random_state=2023)\n","\n","batch_size = 128\n","criterion = nn.BCELoss().to(device=device)"],"metadata":{"id":"k_41havYSoFa","executionInfo":{"status":"ok","timestamp":1702875696778,"user_tz":-330,"elapsed":5,"user":{"displayName":"Nimsara Fernando","userId":"11470797706788239513"}}},"execution_count":13,"outputs":[]},{"cell_type":"code","source":["# Create DataLoader for training and validation sets\n","batch_size = 128\n","\n","train_dataset = list(zip(x_train, y_train))\n","train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n","\n","val_dataset = list(zip(x_val, y_val))\n","val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)\n","\n","# Initialize the model\n","fakebert = FakeBERT(\n","    device,\n","    inductor=True\n",")\n","\n","# Loss function and optimizer\n","criterion = nn.BCELoss().to(device=device)  # Binary Cross-Entropy Loss for binary classification\n","optimizer = optim.Adam(fakebert.parameters(), lr=0.001)\n","\n","d_r = 10**-10\n","scheduler = ExponentialLR(optimizer, gamma=(1.0 - d_r))\n","\n","# Define early stopping parameters\n","patience = 5\n","best_validation_accuracy = 0\n","no_improvement_counter = 0\n","\n","# Training loop\n","num_epochs = 20\n","\n","for epoch in range(num_epochs):\n","    fakebert.train()\n","    total_correct_train = 0\n","    total_samples_train = 0\n","\n","    for inputs, labels in train_loader:\n","        optimizer.zero_grad()\n","        outputs = fakebert(inputs)\n","\n","        # Compute training accuracy\n","        predicted_labels_train = (outputs > 0.5).int()\n","        total_correct_train += (predicted_labels_train.view(-1) == labels.to(device=device)).sum().item()\n","\n","        # Accumulate the sum of batch sizes\n","        total_samples_train += len(labels)\n","\n","        loss = criterion(outputs, torch.as_tensor(labels, dtype=torch.float32).unsqueeze(1).to(device=device))\n","        loss.backward()\n","        optimizer.step()\n","\n","    # Compute training accuracy\n","    train_accuracy = total_correct_train / total_samples_train\n","\n","    # Validation\n","    val_loss = 0.0\n","    total_correct_val = 0\n","    total_samples_val = 0\n","    num_iterations = (len(y_val) + batch_size - 1) // batch_size\n","\n","    fakebert.eval()\n","    with torch.no_grad():\n","        for val_inputs, val_labels in val_loader:\n","            val_outputs = fakebert(val_inputs)\n","\n","            # Compute validation accuracy\n","            predicted_labels_val = (val_outputs > 0.5).int()\n","            total_correct_val += (predicted_labels_val.view(-1) == val_labels.to(device=device)).sum().item()\n","\n","            # Accumulate the sum of batch sizes\n","            total_samples_val += len(val_labels)\n","\n","            val_batch_targets = torch.as_tensor(val_labels, dtype=torch.float32).unsqueeze(1).to(device=device)\n","            ce = criterion(val_outputs, val_batch_targets).item()\n","            val_loss += ce\n","\n","        avg_val_loss = val_loss / len(val_loader)\n","        val_accuracy = total_correct_val / total_samples_val\n","\n","        print(f'Epoch {epoch + 1}/{num_epochs}, Loss: {avg_val_loss:.4f}, Training Accuracy: {train_accuracy:.4f}, Validation Accuracy: {val_accuracy:.4f}')\n","\n","        # Check for early stopping\n","        if val_accuracy > best_validation_accuracy:\n","            best_validation_accuracy = val_accuracy\n","            no_improvement_counter = 0\n","            # Save the trained best fakebert if needed\n","            torch.save(fakebert.state_dict(), '/content/drive/Shareddrives/test/FYP/fake-news/fakebert-twitterus.pth')\n","        else:\n","            no_improvement_counter += 1\n","\n","        # If no improvement for 'patience' consecutive epochs, stop training\n","        if no_improvement_counter >= patience:\n","            print(\"Early stopping triggered. Training stopped.\")\n","            break"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"jswjhN-24bw0","executionInfo":{"status":"ok","timestamp":1702872858871,"user_tz":-330,"elapsed":3347968,"user":{"displayName":"Nimsara Fernando","userId":"11470797706788239513"}},"outputId":"780b0640-7423-4c6c-e1c9-2558a7d91e3f"},"execution_count":10,"outputs":[{"output_type":"stream","name":"stderr","text":["Some weights of RobertaModel were not initialized from the model checkpoint at roberta-base and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 1/20, Loss: 0.1972, Training Accuracy: 0.8450, Validation Accuracy: 0.9273\n","Epoch 2/20, Loss: 0.1721, Training Accuracy: 0.9334, Validation Accuracy: 0.9385\n","Epoch 3/20, Loss: 0.1931, Training Accuracy: 0.9424, Validation Accuracy: 0.9255\n","Epoch 4/20, Loss: 0.1475, Training Accuracy: 0.9472, Validation Accuracy: 0.9481\n","Epoch 5/20, Loss: 0.1569, Training Accuracy: 0.9541, Validation Accuracy: 0.9489\n","Epoch 6/20, Loss: 0.1377, Training Accuracy: 0.9586, Validation Accuracy: 0.9541\n","Epoch 7/20, Loss: 0.1501, Training Accuracy: 0.9641, Validation Accuracy: 0.9506\n","Epoch 8/20, Loss: 0.1713, Training Accuracy: 0.9702, Validation Accuracy: 0.9307\n","Epoch 9/20, Loss: 0.1580, Training Accuracy: 0.9747, Validation Accuracy: 0.9481\n","Epoch 10/20, Loss: 0.1831, Training Accuracy: 0.9816, Validation Accuracy: 0.9411\n","Epoch 11/20, Loss: 0.2096, Training Accuracy: 0.9884, Validation Accuracy: 0.9446\n","Early stopping triggered. Training stopped.\n"]}]},{"cell_type":"code","source":["test_dataset = list(zip(x_test, y_test))\n","test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n","\n","# Create an instance of the model\n","fakebertTwitterUS = FakeBERT(\n","    device,\n","    inductor=True\n",")\n","\n","# Load the saved model state dictionary\n","fakebertTwitterUS.load_state_dict(torch.load('/content/drive/Shareddrives/test/FYP/fake-news/fakebert-twitterus.pth'))\n","\n","# Testing\n","test_loss = 0.0\n","total_correct_test = 0\n","total_samples_test = 0\n","num_iterations = (len(y_test) + batch_size - 1) // batch_size\n","\n","fakebertTwitterUS.eval()\n","with torch.no_grad():\n","    for test_inputs, test_labels in test_loader:\n","        test_outputs = fakebertTwitterUS(test_inputs)\n","\n","        # Compute validation accuracy\n","        predicted_labels_test = (test_outputs > 0.5).int()\n","        total_correct_test += (predicted_labels_test.view(-1) == test_labels.to(device=device)).sum().item()\n","\n","        # Accumulate the sum of batch sizes\n","        total_samples_test += len(test_labels)\n","\n","        test_batch_targets = torch.as_tensor(test_labels, dtype=torch.float32).unsqueeze(1).to(device=device)\n","        ce = criterion(test_outputs, test_batch_targets).item()\n","        test_loss += ce\n","\n","    avg_test_loss = test_loss / len(test_loader)\n","    test_accuracy = total_correct_test / total_samples_test\n","\n","    print(f'Loss: {avg_test_loss:.4f}, Test Accuracy: {test_accuracy:.4f}')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"lyMoqdto5rAw","executionInfo":{"status":"ok","timestamp":1702875791546,"user_tz":-330,"elapsed":87919,"user":{"displayName":"Nimsara Fernando","userId":"11470797706788239513"}},"outputId":"b6eaae53-c5a0-4943-9bf9-b4a6902c0875"},"execution_count":14,"outputs":[{"output_type":"stream","name":"stderr","text":["Some weights of RobertaModel were not initialized from the model checkpoint at roberta-base and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"]},{"output_type":"stream","name":"stdout","text":["Loss: 0.1103, Test Accuracy: 0.9558\n"]}]},{"cell_type":"markdown","source":["#### IMDB Sentiment"],"metadata":{"id":"jrqG2jOwRxu8"}},{"cell_type":"code","source":["file_path = '/content/drive/Shareddrives/test/Sentiment/IMDB Dataset.csv'\n","\n","df = pd.read_csv(file_path, usecols=['sentiment', 'review'])\n","df.dropna(subset=['review'], inplace=True)\n","df.dropna(subset=['sentiment'], inplace=True)\n","\n","df['sentiment'] = df['sentiment'].map({'positive': 1, 'negative': 0})\n","\n","valid_sentiments = [0, 1]\n","df_valid = df[df['sentiment'].isin(valid_sentiments)]\n","df_valid['sentiment'].value_counts()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"jFP-mhoGHei8","executionInfo":{"status":"ok","timestamp":1702875802283,"user_tz":-330,"elapsed":2754,"user":{"displayName":"Nimsara Fernando","userId":"11470797706788239513"}},"outputId":"08eb00a9-4abf-48d7-b244-cfb104727bd9"},"execution_count":15,"outputs":[{"output_type":"execute_result","data":{"text/plain":["1    25000\n","0    25000\n","Name: sentiment, dtype: int64"]},"metadata":{},"execution_count":15}]},{"cell_type":"code","source":["x_train, x_temp, y_train, y_temp = train_test_split(df_valid['review'], df_valid['sentiment'], test_size=0.2, stratify=df_valid['sentiment'], random_state=2023)\n","x_test, x_val, y_test, y_val = train_test_split(x_temp, y_temp, test_size=0.5, stratify=y_temp, random_state=2023)\n","\n","print(f\"y_train\\n {y_train.value_counts()}\")\n","print(f\"y_test\\n {y_test.value_counts()}\")\n","print(f\"y_val\\n {y_val.value_counts()}\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"BYHh0MFTR3o4","executionInfo":{"status":"ok","timestamp":1702875804583,"user_tz":-330,"elapsed":819,"user":{"displayName":"Nimsara Fernando","userId":"11470797706788239513"}},"outputId":"6366a754-76f0-41ff-90ff-c9479cdf3ff4"},"execution_count":16,"outputs":[{"output_type":"stream","name":"stdout","text":["y_train\n"," 1    20000\n","0    20000\n","Name: sentiment, dtype: int64\n","y_test\n"," 1    2500\n","0    2500\n","Name: sentiment, dtype: int64\n","y_val\n"," 1    2500\n","0    2500\n","Name: sentiment, dtype: int64\n"]}]},{"cell_type":"code","source":["# Create DataLoader for training and validation sets\n","batch_size = 128\n","\n","train_dataset = list(zip(x_train, y_train))\n","train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n","\n","val_dataset = list(zip(x_val, y_val))\n","val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)\n","\n","# Initialize the model\n","fakebert = FakeBERT(\n","    device,\n","    inductor=True\n",")\n","\n","# Loss function and optimizer\n","criterion = nn.BCELoss().to(device=device)  # Binary Cross-Entropy Loss for binary classification\n","optimizer = optim.Adam(fakebert.parameters(), lr=0.001)\n","\n","d_r = 10**-10\n","scheduler = ExponentialLR(optimizer, gamma=(1.0 - d_r))\n","\n","# Define early stopping parameters\n","patience = 5\n","best_validation_accuracy = 0\n","no_improvement_counter = 0\n","\n","# Training loop\n","num_epochs = 20\n","\n","for epoch in range(num_epochs):\n","    fakebert.train()\n","    total_correct_train = 0\n","    total_samples_train = 0\n","\n","    for inputs, labels in train_loader:\n","        optimizer.zero_grad()\n","        outputs = fakebert(inputs)\n","\n","        # Compute training accuracy\n","        predicted_labels_train = (outputs > 0.5).int()\n","        total_correct_train += (predicted_labels_train.view(-1) == labels.to(device=device)).sum().item()\n","\n","        # Accumulate the sum of batch sizes\n","        total_samples_train += len(labels)\n","\n","        loss = criterion(outputs, torch.as_tensor(labels, dtype=torch.float32).unsqueeze(1).to(device=device))\n","        loss.backward()\n","        optimizer.step()\n","\n","    # Compute training accuracy\n","    train_accuracy = total_correct_train / total_samples_train\n","\n","    # Validation\n","    val_loss = 0.0\n","    total_correct_val = 0\n","    total_samples_val = 0\n","    num_iterations = (len(y_val) + batch_size - 1) // batch_size\n","\n","    fakebert.eval()\n","    with torch.no_grad():\n","        for val_inputs, val_labels in val_loader:\n","            val_outputs = fakebert(val_inputs)\n","\n","            # Compute validation accuracy\n","            predicted_labels_val = (val_outputs > 0.5).int()\n","            total_correct_val += (predicted_labels_val.view(-1) == val_labels.to(device=device)).sum().item()\n","\n","            # Accumulate the sum of batch sizes\n","            total_samples_val += len(val_labels)\n","\n","            val_batch_targets = torch.as_tensor(val_labels, dtype=torch.float32).unsqueeze(1).to(device=device)\n","            ce = criterion(val_outputs, val_batch_targets).item()\n","            val_loss += ce\n","\n","        avg_val_loss = val_loss / len(val_loader)\n","        val_accuracy = total_correct_val / total_samples_val\n","\n","        print(f'Epoch {epoch + 1}/{num_epochs}, Loss: {avg_val_loss:.4f}, Training Accuracy: {train_accuracy:.4f}, Validation Accuracy: {val_accuracy:.4f}')\n","\n","        # Check for early stopping\n","        if val_accuracy > best_validation_accuracy:\n","            best_validation_accuracy = val_accuracy\n","            no_improvement_counter = 0\n","            # Save the trained best fakebert if needed\n","            torch.save(fakebert.state_dict(), '/content/drive/Shareddrives/test/FYP/fake-news/fakebert-imdb.pth')\n","        else:\n","            no_improvement_counter += 1\n","\n","        # If no improvement for 'patience' consecutive epochs, stop training\n","        if no_improvement_counter >= patience:\n","            print(\"Early stopping triggered. Training stopped.\")\n","            break"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"qnLpKeb8R7BC","outputId":"1cf5d1c0-6b85-441e-8b44-7b42d4ccfde3"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["Some weights of RobertaModel were not initialized from the model checkpoint at roberta-base and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 1/20, Loss: 0.1729, Training Accuracy: 0.8937, Validation Accuracy: 0.9370\n","Epoch 2/20, Loss: 0.1676, Training Accuracy: 0.9330, Validation Accuracy: 0.9378\n","Epoch 3/20, Loss: 0.1912, Training Accuracy: 0.9433, Validation Accuracy: 0.9290\n","Epoch 4/20, Loss: 0.1697, Training Accuracy: 0.9507, Validation Accuracy: 0.9396\n","Epoch 5/20, Loss: 0.1674, Training Accuracy: 0.9584, Validation Accuracy: 0.9382\n","Epoch 6/20, Loss: 0.1757, Training Accuracy: 0.9668, Validation Accuracy: 0.9412\n","Epoch 7/20, Loss: 0.1954, Training Accuracy: 0.9747, Validation Accuracy: 0.9412\n","Epoch 8/20, Loss: 0.2235, Training Accuracy: 0.9796, Validation Accuracy: 0.9378\n"]}]},{"cell_type":"code","source":["test_dataset = list(zip(x_test, y_test))\n","test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n","\n","# Create an instance of the model\n","fakebertIMDB = FakeBERT(\n","    device,\n","    inductor=True\n",")\n","\n","# Load the saved model state dictionary\n","fakebertIMDB.load_state_dict(torch.load('/content/drive/Shareddrives/test/FYP/fake-news/fakebert-imdb.pth'))\n","\n","# Testing\n","test_loss = 0.0\n","total_correct_test = 0\n","total_samples_test = 0\n","num_iterations = (len(y_test) + batch_size - 1) // batch_size\n","\n","fakebertIMDB.eval()\n","with torch.no_grad():\n","    for test_inputs, test_labels in test_loader:\n","        test_outputs = fakebertIMDB(test_inputs)\n","\n","        # Compute validation accuracy\n","        predicted_labels_test = (test_outputs > 0.5).int()\n","        total_correct_test += (predicted_labels_test.view(-1) == test_labels.to(device=device)).sum().item()\n","\n","        # Accumulate the sum of batch sizes\n","        total_samples_test += len(test_labels)\n","\n","        test_batch_targets = torch.as_tensor(test_labels, dtype=torch.float32).unsqueeze(1).to(device=device)\n","        ce = criterion(test_outputs, test_batch_targets).item()\n","        test_loss += ce\n","\n","    avg_test_loss = test_loss / len(test_loader)\n","    test_accuracy = total_correct_test / total_samples_test\n","\n","    print(f'Loss: {avg_test_loss:.4f}, Test Accuracy: {test_accuracy:.4f}')"],"metadata":{"id":"mGjsqKmvR5Xf"},"execution_count":null,"outputs":[]}]}